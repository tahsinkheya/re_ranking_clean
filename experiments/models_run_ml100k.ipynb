{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this file we run models for the ml100k dataset and then we genrate and store the topk recommendations and scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cornac.data import Reader\n",
    "from cornac.datasets import movielens\n",
    "from cornac.data import Dataset, FeatureModality\n",
    "from cornac.eval_methods import RatioSplit, StratifiedSplit\n",
    "from cornac.metrics import RMSE\n",
    "from cornac.models import MF,VAECF, NeuMF,PMF, WMF\n",
    "# from MF import MF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cornac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data_pd = pd.read_csv(\n",
    "    \"../data/ml-100K/indexed_interactions.csv\",\n",
    "    sep=\"\\t\",\n",
    "    header=0,\n",
    "    names=[\"userID\", \"itemID\", \"Rating\", \"Timestamp\"],\n",
    ")\n",
    "rating_data = rating_data_pd.to_numpy()\n",
    "rating_data.__len__()\n",
    "rating_data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movie = '../data/ml-100K/i_id_mapping_genre.csv'\n",
    "\n",
    "df_movie = pd.read_csv(movie, sep='\\t')\n",
    "print(f'shape: {df_movie.shape}')\n",
    "\n",
    "\n",
    "df_movie.columns = [\"item_id\", \"Name\",\"genres\",\"itemID\"]\n",
    "df_movie[:4]\n",
    "movies = df_movie.sort_values(by=\"itemID\")\n",
    "unique_genres = [\n",
    "    \"Action\",\n",
    "    \"Thriller\",\n",
    "    \"Romance\",\n",
    "    \"Western\",\n",
    "    \"Children's\",\n",
    "    \"Mystery\",\n",
    "    \"Fantasy\",\n",
    "    \"Film-Noir\",\n",
    "    \"Documentary\",\n",
    "    \"Comedy\",\n",
    "    \"Adventure\",\n",
    "    \"Sci-Fi\",\n",
    "    \"Horror\",\n",
    "    \"Crime\",\n",
    "    \"Musical\",\n",
    "    \"War\",\n",
    "    \"Animation\",\n",
    "    \"Drama\",\n",
    "]\n",
    "for genre in unique_genres:\n",
    "    movies[genre] = 0\n",
    "    \n",
    "for index, row in movies.iterrows():\n",
    "    genres = row[\"genres\"].split(\"|\")\n",
    "    for genre in genres:\n",
    "        movies.at[index, genre] = 1\n",
    "movies\n",
    "\n",
    "\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.drop(columns=[\"item_id\"])\n",
    "movies = movies.sort_values(by=\"itemID\")\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"../data/ml-100k/u_id_mapping_demographic_.csv\", sep=\"\\t\")\n",
    "users = users.sort_values(by=\"userID\")\n",
    "users = users.drop(columns=users.columns[0])\n",
    "gender_map = {\"M\": 0, \"F\": 1}\n",
    "users[\"Gender\"] = users[\"Gender\"].map(gender_map)\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rating_data\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_split = StratifiedSplit(\n",
    "    data=dataset,\n",
    "    test_size=0.2,\n",
    "    rating_threshold=0.0,\n",
    "    seed=123,\n",
    "    verbose=True,\n",
    "    chrono=True,\n",
    ")\n",
    "\n",
    "hr_10 = cornac.metrics.HitRatio(k=20)\n",
    "ndcg_10 = cornac.metrics.NDCG(k=20)\n",
    "recall_10 = cornac.metrics.Recall(k=20)\n",
    "prec_10 = cornac.metrics.Precision(k=20)\n",
    "auc = cornac.metrics.AUC()\n",
    "map = cornac.metrics.MAP()\n",
    "\n",
    "epochs = [20, 40, 60, 80, 100]\n",
    "models = []\n",
    "\n",
    "for i in range(len(epochs)):\n",
    "    models.append(\n",
    "       WMF(name=f'WMF{epochs[i]}', k=200, lambda_u=0.01, lambda_v=0.01, a=1, b=0.01, learning_rate=0.001, batch_size=128, max_iter=epochs[i], trainable=True, verbose=True, init_params=None, seed=123)\n",
    "    )\n",
    "# model = WMF(name=f'WMF{100}', k=200, lambda_u=0.01, lambda_v=0.01, a=1, b=0.01, learning_rate=0.001, batch_size=128, max_iter=100, trainable=True, verbose=True, init_params=None, seed=123)\n",
    "\n",
    "# model = MF(\n",
    "#             name=f\"MF{40}\",\n",
    "#             k=10,\n",
    "#             backend=\"cpu\",\n",
    "#             optimizer=\"adam\",\n",
    "#             max_iter=40,\n",
    "#             learning_rate=0.01,\n",
    "#             batch_size=256,\n",
    "#             lambda_reg=0.02,\n",
    "#             dropout=0.0,\n",
    "#             use_bias=True,\n",
    "#             early_stop=False,\n",
    "#             num_threads=0,\n",
    "#             trainable=True,\n",
    "#             verbose=False,\n",
    "#             init_params=None,\n",
    "#             seed=123,\n",
    "#         )\n",
    "\n",
    "# model =  NeuMF(\n",
    "#            name=f\"NeuMFe={80}\",\n",
    "#             num_factors=8,\n",
    "#             layers=( 32, 16, 8),\n",
    "#             act_fn=\"sigmoid\",\n",
    "#             reg=0.0,\n",
    "#             num_epochs=80,\n",
    "#             batch_size=256,\n",
    "#             num_neg=3,\n",
    "#             lr=0.001,\n",
    "#             learner=\"adam\",\n",
    "#             backend=\"tensorflow\",\n",
    "#             early_stopping=None,\n",
    "#             trainable=True,\n",
    "#             verbose=True,\n",
    "#             seed=123,\n",
    "#         )\n",
    "# # model=VAECF(k=10, autoencoder_structure=[20], name=\"vae100\",act_fn=\"tanh\", likelihood=\"mult\", n_epochs=100, batch_size=100, learning_rate=0.001, beta=1.0, seed=123, verbose=True)\n",
    "\n",
    "# models = [model]\n",
    "cornac.Experiment(\n",
    "    ratio_split, models=models, metrics=[hr_10, ndcg_10, recall_10, auc, prec_10, map]\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [models[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = users[\"userID\"].to_numpy()\n",
    "item_ids = movies[\"itemID\"].to_numpy()\n",
    "user_ids.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top_k ratings for all users:\n",
    "top_k = 100\n",
    "reco_matrix = np.zeros((len(models), len(user_ids), top_k), dtype=int)\n",
    "reco_matrix_mapped_items = np.zeros(\n",
    "    (len(models), len(user_ids), len(item_ids)), dtype=int\n",
    ")\n",
    "reco_matrix_mapped_scores = np.zeros(\n",
    "    (len(models), len(user_ids), len(item_ids)), dtype=float\n",
    ")\n",
    "reco_matrix_all = np.zeros((len(models), len(user_ids), len(item_ids)), dtype=int)\n",
    "for u in user_ids:\n",
    "    for i in range(len(models)):\n",
    "        reco_items = models[i].recommend(u)\n",
    "        items_mapped, mapped_scores = models[i].rank(\n",
    "            user_idx=u, item_indices=list(item_ids)\n",
    "        )\n",
    "        reco_matrix_mapped_items[i][u] = items_mapped\n",
    "        reco_matrix_mapped_scores[i][u] = mapped_scores\n",
    "        reco_matrix_all[i][u] = reco_items\n",
    "        reco_matrix[i][u] = reco_items[:top_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set_data = pd.DataFrame(ratio_split.test_set.uir_tuple).transpose()\n",
    "# test_set_data.columns = [\"uid\", \"iid\", \"rating\"]\n",
    "# test_set_data = test_set_data.astype({\"uid\": \"int\", \"iid\": \"int\", \"rating\": \"int\"})\n",
    "# r_global_uid_map = {v: k for k, v in ratio_split.global_uid_map.items()}\n",
    "# r_global_iid_map = {v: k for k, v in ratio_split.global_iid_map.items()}\n",
    "\n",
    "# test_set_data[\"uid\"] = test_set_data[\"uid\"].map(r_global_uid_map)\n",
    "# test_set_data[\"iid\"] = test_set_data[\"iid\"].map(r_global_iid_map)\n",
    "# test_set_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set_data = pd.DataFrame(ratio_split.train_set.uir_tuple).transpose()\n",
    "# train_set_data.columns = [\"uid\", \"iid\", \"rating\"]\n",
    "# train_set_data = train_set_data.astype({\"uid\": \"int\", \"iid\": \"int\", \"rating\": \"int\"})\n",
    "# r_global_uid_map = {v: k for k, v in ratio_split.global_uid_map.items()}\n",
    "# r_global_iid_map = {v: k for k, v in ratio_split.global_iid_map.items()}\n",
    "\n",
    "# train_set_data[\"uid\"] = train_set_data[\"uid\"].map(r_global_uid_map)\n",
    "# train_set_data[\"iid\"] = train_set_data[\"iid\"].map(r_global_iid_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set_data.to_csv(\"testing_set_seed123_ml100k.csv\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set_data.to_csv(\"training_set_seed123_ml100k.csv\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"reco_matrix_wmf_100k_100\",reco_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# uid_map (OrderDict, required) â€“ The dictionary containing mapping from user original ids to mapped integer indices.\n",
    "\n",
    "# iid_map (OrderDict, required) â€“ The dictionary containing mapping from item original ids to mapped integer indices.\n",
    "sorted_by_values = OrderedDict(sorted(models[0].iid_map.items(), key=lambda item: item[1]))\n",
    "keys_sorted_by_values = list(sorted_by_values.keys())\n",
    "\n",
    "reco_items_scores_all = [OrderedDict() for _ in range(len(user_ids))]\n",
    "\n",
    "for u in user_ids:\n",
    "    actual_index_u = u\n",
    "    mapped_index_u = models[0].uid_map[actual_index_u]\n",
    "    # print(f\"u {u} mapped u {mapped_index_u}\")\n",
    "    \n",
    "    # for i in item_ids:\n",
    "    mapped_scores = reco_matrix_mapped_scores[0][mapped_index_u]\n",
    "    ordered_dict = OrderedDict(zip(keys_sorted_by_values, mapped_scores))\n",
    "    reco_items_scores_all[actual_index_u] = ordered_dict\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('score_dicts_wmf100k.pkl', 'wb') as file:\n",
    "    pickle.dump(reco_items_scores_all, file)\n",
    "\n",
    "print(\"List of OrderedDicts saved to 'score_dicts.pkl'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "re-ranking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
