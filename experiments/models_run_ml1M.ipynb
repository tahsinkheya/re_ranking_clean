{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this file we run models for the ml1m dtaset and then we genrate and store the topk recommendations and scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from cornac.eval_methods import StratifiedSplit\n",
    "from cornac.metrics import RMSE\n",
    "from cornac.models import  MF, VAECF, NeuMF, PMF, WMF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cornac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data_pd = pd.read_csv(\n",
    "    \"../data/ml-1m/indexed_interactions.csv\",\n",
    "    sep=\"\\t\",\n",
    "    header=0,\n",
    "    names=[\"userID\", \"itemID\", \"Rating\", \"Timestamp\"],\n",
    ")\n",
    "rating_data = rating_data_pd.to_numpy()\n",
    "rating_data.__len__()\n",
    "rating_data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = \"../data/ml-1m/i_id_mapping_genre.csv\"\n",
    "\n",
    "df_movie = pd.read_csv(movie, sep=\"\\t\")\n",
    "print(f\"shape: {df_movie.shape}\")\n",
    "\n",
    "\n",
    "df_movie.columns = [\"item_id\", \"Name\", \"genres\", \"itemID\"]\n",
    "df_movie[:4]\n",
    "movies = df_movie.sort_values(by=\"itemID\")\n",
    "unique_genres = [\n",
    "    \"Action\",\n",
    "    \"Thriller\",\n",
    "    \"Romance\",\n",
    "    \"Western\",\n",
    "    \"Children's\",\n",
    "    \"Mystery\",\n",
    "    \"Fantasy\",\n",
    "    \"Film-Noir\",\n",
    "    \"Documentary\",\n",
    "    \"Comedy\",\n",
    "    \"Adventure\",\n",
    "    \"Sci-Fi\",\n",
    "    \"Horror\",\n",
    "    \"Crime\",\n",
    "    \"Musical\",\n",
    "    \"War\",\n",
    "    \"Animation\",\n",
    "    \"Drama\",\n",
    "]\n",
    "for genre in unique_genres:\n",
    "    movies[genre] = 0\n",
    "\n",
    "for index, row in movies.iterrows():\n",
    "    genres = row[\"genres\"].split(\"|\")\n",
    "    for genre in genres:\n",
    "        movies.at[index, genre] = 1\n",
    "movies\n",
    "\n",
    "\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.drop(columns=[\"item_id\"])\n",
    "movies = movies.sort_values(by=\"itemID\")\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"../data/ml-1m/u_id_mapping_demographic.csv\", sep=\"\\t\")\n",
    "# users\n",
    "\n",
    "\n",
    "users = users.sort_values(by=\"userID\")\n",
    "\n",
    "users = users.drop(columns=users.columns[0])\n",
    "gender_map = {\"M\": 0, \"F\": 1}\n",
    "users[\"Gender\"] = users[\"Gender\"].map(gender_map)\n",
    "# user_features_numpy = users.to_numpy()\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rating_data\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_split = StratifiedSplit(\n",
    "    data=dataset,\n",
    "    test_size=0.2,\n",
    "    rating_threshold=0.0,\n",
    "    seed=123,\n",
    "    verbose=True,\n",
    "    chrono=True,\n",
    "    exclude_unknowns=False,\n",
    ")\n",
    "\n",
    "hr_10 = cornac.metrics.HitRatio(k=20)\n",
    "ndcg_10 = cornac.metrics.NDCG(k=20)\n",
    "recall_10 = cornac.metrics.Recall(k=20)\n",
    "prec_10 = cornac.metrics.Precision(k=20)\n",
    "auc = cornac.metrics.AUC()\n",
    "map = cornac.metrics.MAP()\n",
    "\n",
    "epochs = [40, 60, 80, 100, 120, 140, 160, 180, 200]\n",
    "\n",
    "models = []\n",
    "\n",
    "   \n",
    "for i in range(len(epochs)):\n",
    "    models.append(\n",
    "      MF(\n",
    "            name=f\"MF{epochs[i]}\",\n",
    "            k=40,\n",
    "            backend=\"cpu\",\n",
    "            optimizer=\"adam\",\n",
    "            max_iter=epochs[i],\n",
    "            learning_rate=0.001,\n",
    "            batch_size=1024,\n",
    "            # lambda_reg=0.02,\n",
    "            dropout=0.0,\n",
    "            use_bias=True,\n",
    "            early_stop=False,\n",
    "            num_threads=0,\n",
    "            trainable=True,\n",
    "            verbose=True,\n",
    "            init_params=None,\n",
    "            seed=123,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "#   MF(\n",
    "#             name=f\"MF{epochs[i]}\",\n",
    "#             k=40,\n",
    "#             backend=\"cpu\",\n",
    "#             optimizer=\"adam\",\n",
    "#             max_iter=200,\n",
    "#             learning_rate=0.001,\n",
    "#             batch_size=1024,\n",
    "#             # lambda_reg=0.02,\n",
    "#             dropout=0.0,\n",
    "#             use_bias=True,\n",
    "#             early_stop=False,\n",
    "#             num_threads=0,\n",
    "#             trainable=True,\n",
    "#             verbose=True,\n",
    "#             init_params=None,\n",
    "#             seed=123,\n",
    "#         )\n",
    "# WMF(name=f'WMF{epochs[i]}', k=200, lambda_u=0.01, lambda_v=0.01, a=1, b=0.01, learning_rate=0.001, batch_size=128, max_iter=80,\n",
    "# trainable=True, verbose=True, init_params=None, seed=123) \n",
    "    \n",
    "    # VAECF(\n",
    "    #         k=50,\n",
    "    #         autoencoder_structure=[ 128, 64],\n",
    "    #         act_fn=\"relu\",\n",
    "    #         likelihood=\"bern\",\n",
    "    #         n_epochs=40,\n",
    "    #         batch_size=512,\n",
    "    #         learning_rate=0.0005, \n",
    "    #         alpha=alpha_values[i],\n",
    "    #         top_k=50,\n",
    "    #         beta=1,\n",
    "    #         name=f\"a={alpha_values[i]} vae\",\n",
    "    #         seed=123,\n",
    "    #         verbose=True,save_dir=\"./model_saved/\"\n",
    "    #         # early_stopping=True\n",
    "        \n",
    "    # ))\n",
    "\n",
    "\n",
    "#  NeuMF(\n",
    "#             name=f\"NeuMFe={epochs[i]}\",\n",
    "#             num_factors=16,\n",
    "#             layers=(64, 32,16),\n",
    "#             act_fn=\"sigmoid\",\n",
    "#             reg=0.0,\n",
    "#             num_epochs=40,\n",
    "#             batch_size=1024,\n",
    "#             num_neg=3,\n",
    "#             lr=0.001,\n",
    "#             learner=\"adam\",\n",
    "#             backend=\"tensorflow\",\n",
    "#             early_stopping=None,\n",
    "#             trainable=True,\n",
    "#             verbose=True,\n",
    "#             seed=123,\n",
    "#         )\n",
    "\n",
    "# models = [model]\n",
    "cornac.Experiment(\n",
    "    ratio_split, models=models, metrics=[hr_10, ndcg_10, recall_10, auc, prec_10, map]\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = users[\"userID\"].to_numpy()\n",
    "item_ids = movies[\"itemID\"].to_numpy()\n",
    "user_ids.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[models] # select 1 model here. choose best one depending on perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top_k ratings for all users:\n",
    "top_k = 1000\n",
    "reco_matrix = np.zeros((len(models), len(user_ids), top_k), dtype=int)\n",
    "reco_matrix_mapped_items = np.zeros(\n",
    "    (len(models), len(user_ids), len(item_ids)), dtype=int\n",
    ")\n",
    "reco_matrix_mapped_scores = np.zeros(\n",
    "    (len(models), len(user_ids), len(item_ids)), dtype=float\n",
    ")\n",
    "reco_matrix_all = np.zeros((len(models), len(user_ids), len(item_ids)), dtype=int)\n",
    "\n",
    "\n",
    "for u in user_ids:\n",
    "    for i in range(len(models)):\n",
    "        reco_items = models[i].recommend(u)\n",
    "        # print(reco_items.__len__())\n",
    "        items_mapped, mapped_scores = models[i].rank(\n",
    "            user_idx=u, item_indices=list(item_ids)\n",
    "        )\n",
    "        reco_matrix_mapped_items[i][u] = items_mapped\n",
    "        reco_matrix_mapped_scores[i][u] = mapped_scores\n",
    "        reco_matrix_all[i][u] = reco_items\n",
    "        reco_matrix[i][u] = reco_items[:top_k]\n",
    "\n",
    "        # print(reco_matrix[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set_data = pd.DataFrame(ratio_split.test_set.uir_tuple).transpose()\n",
    "# test_set_data.columns = [\"uid\", \"iid\", \"rating\"]\n",
    "# test_set_data = test_set_data.astype({\"uid\": \"int\", \"iid\": \"int\", \"rating\": \"int\"})\n",
    "# r_global_uid_map = {v: k for k, v in ratio_split.global_uid_map.items()}\n",
    "# r_global_iid_map = {v: k for k, v in ratio_split.global_iid_map.items()}\n",
    "\n",
    "# test_set_data[\"uid\"] = test_set_data[\"uid\"].map(r_global_uid_map)\n",
    "# test_set_data[\"iid\"] = test_set_data[\"iid\"].map(r_global_iid_map)\n",
    "# test_set_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set_data = pd.DataFrame(ratio_split.train_set.uir_tuple).transpose()\n",
    "# train_set_data.columns = [\"uid\", \"iid\", \"rating\"]\n",
    "# train_set_data = train_set_data.astype({\"uid\": \"int\", \"iid\": \"int\", \"rating\": \"int\"})\n",
    "# r_global_uid_map = {v: k for k, v in ratio_split.global_uid_map.items()}\n",
    "# r_global_iid_map = {v: k for k, v in ratio_split.global_iid_map.items()}\n",
    "\n",
    "# train_set_data[\"uid\"] = train_set_data[\"uid\"].map(r_global_uid_map)\n",
    "# train_set_data[\"iid\"] = train_set_data[\"iid\"].map(r_global_iid_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"reco_matrix_mf_1m_1000\", reco_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "sorted_by_values = OrderedDict(\n",
    "    sorted(models[0].iid_map.items(), key=lambda item: item[1])\n",
    ")\n",
    "keys_sorted_by_values = list(sorted_by_values.keys())\n",
    "\n",
    "reco_items_scores_all = [OrderedDict() for _ in range(len(user_ids))]\n",
    "\n",
    "for u in user_ids:\n",
    "    actual_index_u = u\n",
    "    mapped_index_u = models[0].uid_map[actual_index_u]\n",
    "    # print(f\"u {u} mapped u {mapped_index_u}\")\n",
    "\n",
    "    # for i in item_ids:\n",
    "    mapped_scores = reco_matrix_mapped_scores[0][mapped_index_u]\n",
    "    ordered_dict = OrderedDict(zip(keys_sorted_by_values, mapped_scores))\n",
    "    reco_items_scores_all[actual_index_u] = ordered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"score_dicts_mf1m.pkl\", \"wb\") as file:\n",
    "    pickle.dump(reco_items_scores_all, file)\n",
    "\n",
    "print(\"List of OrderedDicts saved to 'score_dicts.pkl'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "re-ranking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
